{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T04:03:22.386478Z",
     "start_time": "2025-09-18T04:03:22.055540Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import timeit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d01bfd5c2ec232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 4039592 stored elements and shape (29272, 5000)>\n",
      "  Coords\tValues\n",
      "  (0, 4847)\t1\n",
      "  (0, 1377)\t1\n",
      "  (0, 4646)\t12\n",
      "  (0, 487)\t1\n",
      "  (0, 3346)\t3\n",
      "  (0, 4771)\t1\n",
      "  (0, 3413)\t1\n",
      "  (0, 4900)\t2\n",
      "  (0, 2170)\t2\n",
      "  (0, 719)\t2\n",
      "  (0, 2895)\t1\n",
      "  (0, 4393)\t4\n",
      "  (0, 1073)\t14\n",
      "  (0, 3297)\t3\n",
      "  (0, 2987)\t1\n",
      "  (0, 1970)\t14\n",
      "  (0, 4420)\t3\n",
      "  (0, 3342)\t1\n",
      "  (0, 2722)\t3\n",
      "  (0, 2222)\t2\n",
      "  (0, 1375)\t1\n",
      "  (0, 966)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 1891)\t1\n",
      "  (0, 4578)\t2\n",
      "  :\t:\n",
      "  (29271, 2746)\t1\n",
      "  (29271, 3898)\t13\n",
      "  (29271, 710)\t1\n",
      "  (29271, 1216)\t2\n",
      "  (29271, 999)\t1\n",
      "  (29271, 2537)\t1\n",
      "  (29271, 4123)\t1\n",
      "  (29271, 4489)\t1\n",
      "  (29271, 1452)\t1\n",
      "  (29271, 4000)\t1\n",
      "  (29271, 2590)\t1\n",
      "  (29271, 4419)\t1\n",
      "  (29271, 2909)\t1\n",
      "  (29271, 4934)\t1\n",
      "  (29271, 1779)\t1\n",
      "  (29271, 644)\t1\n",
      "  (29271, 2146)\t1\n",
      "  (29271, 2827)\t2\n",
      "  (29271, 4806)\t1\n",
      "  (29271, 3861)\t1\n",
      "  (29271, 3470)\t1\n",
      "  (29271, 1940)\t1\n",
      "  (29271, 1245)\t1\n",
      "  (29271, 621)\t2\n",
      "  (29271, 3546)\t1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "valid_df = pd.read_csv('data/valid.csv')\n",
    "\n",
    "#pre-cleaning EDA\n",
    "# print(\"---------------Pre-cleaning EDA---------------\")\n",
    "# print(\"- Training data shape: \", train_df.shape)\n",
    "# print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "# print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "counts = train_df['labels'].value_counts()\n",
    "train_df['text_length'] = train_df['text'].str.split().str.len()\n",
    "\n",
    "#clean\n",
    "stopwords = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am',\n",
    "    'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because',\n",
    "    'been', 'before', 'being', 'below', 'between', 'both', 'but',\n",
    "    'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\",\n",
    "    'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    "    'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has',\n",
    "    \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\",\n",
    "    \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him',\n",
    "    'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\",\n",
    "    \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its',\n",
    "    'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my',\n",
    "    'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only',\n",
    "    'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out',\n",
    "    'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\",\n",
    "    \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "    'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves',\n",
    "    'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\",\n",
    "    \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too',\n",
    "    'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\",\n",
    "    \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\",\n",
    "    'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who',\n",
    "    \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would',\n",
    "    \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your',\n",
    "    'yours', 'yourself', 'yourselves'\n",
    "]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    filtered = []\n",
    "    for w in words:\n",
    "        if w not in stopwords and len(w) > 2 and w.isalpha():\n",
    "            filtered.append(w)\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['text'] = df['text'].apply(clean_text).apply(remove_stopwords)\n",
    "    df['title'] = df['title'].apply(clean_text).apply(remove_stopwords)\n",
    "    df['full'] = df['text'] + ' ' + df['title']\n",
    "    df['full'] = df['full'].str.strip()\n",
    "train_df = train_df.drop_duplicates(subset='full', keep='first')\n",
    "\n",
    "#tackle labels imbalance\n",
    "train_df = pd.concat([train_df, train_df[train_df['labels'] == 'true']], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#post-cleaning EDA\n",
    "# print(\"---------------Post-cleaning EDA---------------\")\n",
    "# print(\"- Training data shape: \", train_df.shape)\n",
    "# print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "# print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "\n",
    "#feature extract\n",
    "bow = CountVectorizer(stop_words=stopwords, max_features=5000)\n",
    "X_train = bow.fit_transform(train_df['full'])\n",
    "X_test = bow.transform(test_df['full']).toarray()\n",
    "X_valid = bow.transform(valid_df['full']).toarray()\n",
    "Y_train = np.array(train_df['labels'])\n",
    "Y_test = np.array(test_df['labels'])\n",
    "Y_valid = np.array(valid_df['labels'])\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4072201",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57615195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.classes = None\n",
    "        self.class_prior = None\n",
    "        self.prob = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.classes = np.unique(Y)\n",
    "\n",
    "        class_cnt = []\n",
    "        for c in self.classes:\n",
    "            class_cnt.append(len(Y[Y==c]))\n",
    "        self.class_prior = np.log(np.array(class_cnt) / len(Y))\n",
    "\n",
    "        words_cnt = []\n",
    "        for c in self.classes:\n",
    "            Xc = X[Y == c]\n",
    "            cnt = np.array(Xc.sum(axis=0)).ravel() + self.alpha\n",
    "            words_cnt.append(cnt)\n",
    "        total = np.array(words_cnt).sum(axis=1).reshape(-1, 1)\n",
    "        self.prob = np.log(words_cnt / total)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = X.dot(self.prob.T) + self.class_prior\n",
    "        return self.classes[np.argmax(prediction, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468a1975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Multinomial NB accuracy valid:  0.9023516772114122\n",
      "- Average training time: 0.030381453996524213\n",
      "- Test report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.69      0.93      0.79      1655\n",
      "        true       0.98      0.90      0.94      6723\n",
      "\n",
      "    accuracy                           0.90      8378\n",
      "   macro avg       0.83      0.91      0.86      8378\n",
      "weighted avg       0.92      0.90      0.91      8378\n",
      "\n",
      "- Multinomial NB accuracy test after tuning:  0.9031988541417999\n",
      "-Best parameter: alpha = 2.8500000000000014\n",
      "-Test report after tunning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.69      0.93      0.79      1655\n",
      "        true       0.98      0.90      0.94      6723\n",
      "\n",
      "    accuracy                           0.90      8378\n",
      "   macro avg       0.84      0.91      0.86      8378\n",
      "weighted avg       0.92      0.90      0.91      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMNB = MultinomialNaiveBayes()\n",
    "time_taken = timeit.timeit(\n",
    "    stmt=\"modelMNB.fit(X_train, Y_train)\",\n",
    "    setup=\"from __main__ import modelMNB, X_train, Y_train\",\n",
    "    number=50\n",
    ")\n",
    "modelMNB.fit(X_train, Y_train)\n",
    "y_valid_predMNB = modelMNB.predict(X_valid)\n",
    "print(\"- Multinomial NB accuracy valid: \", accuracy_score(Y_valid, y_valid_predMNB))\n",
    "print(\"- Average training time:\", time_taken / 50)\n",
    "y_test_predMNB = modelMNB.predict(X_test)\n",
    "print(\"- Test report: \\n\", classification_report(Y_test, y_test_predMNB))\n",
    "\n",
    "#fine tuning\n",
    "best_alpha = 0\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "alphas = np.arange(1.5, 3.01, 0.05)\n",
    "for a in alphas:\n",
    "    modelMNB = MultinomialNaiveBayes(alpha=a)\n",
    "    modelMNB.fit(X_train, Y_train)\n",
    "    y_test_predMNB = modelMNB.predict(X_test)\n",
    "    curr_acc = accuracy_score(Y_test, y_test_predMNB)\n",
    "    if (curr_acc > best_acc):\n",
    "        best_acc = curr_acc\n",
    "        best_alpha = a\n",
    "        best_pred = y_test_predMNB\n",
    "print(\"- Multinomial NB accuracy test after tuning: \", best_acc)\n",
    "print(\"-Best parameter: alpha =\", best_alpha)\n",
    "print(\"-Test report after tunning:\\n\", classification_report(Y_test, y_test_predMNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6302d",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22f00762",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def distance(x, y):\n",
    "        if hasattr(x, 'toarray'):\n",
    "            x = x.toarray().ravel()\n",
    "        else:\n",
    "            x = x.ravel()\n",
    "        y = y.ravel()\n",
    "        return np.sqrt(np.sum((x - y) ** 2))\n",
    "class KMC:\n",
    "    def __init__(self, k=3, max_iters=100, tol=0.0001):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "\n",
    "    def assign_clusters(self, X):\n",
    "        clusters = []\n",
    "        for x in X:\n",
    "            min_dist = 10000000000\n",
    "            closest_cluster = -1\n",
    "            for i, c in enumerate(self.centroids):\n",
    "                dist = distance(x, c)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_cluster = i\n",
    "            clusters.append(closest_cluster)\n",
    "        return np.array(clusters)\n",
    "    \n",
    "    def compute_centroids(self, X, clusters):\n",
    "        new_centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            points = X[clusters == i]\n",
    "            if len(points) > 0:\n",
    "                new_centroids[i] = points.mean(axis=0)\n",
    "            else:\n",
    "                new_centroids[i] = self.centroids[i]\n",
    "        return new_centroids\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "        centroids_id = np.random.choice(X.shape[0], size = self.k, replace=False)\n",
    "        self.centroids = X[centroids_id]\n",
    "        for i in range(self.max_iters):\n",
    "            clusters = self.assign_clusters(X)\n",
    "            new_centroids = self.compute_centroids(X, clusters)\n",
    "            if np.linalg.norm(new_centroids - self.centroids) < self.tol:\n",
    "                break\n",
    "            self.centroids = new_centroids\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "        return self.assign_clusters(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b031799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(clusters, y_train, k):\n",
    "    mapping = {}\n",
    "    for cl in range(k):\n",
    "        a = (clusters == cl)\n",
    "        label_cnt = np.bincount(y_train[a])\n",
    "        if len(label_cnt) == 0:\n",
    "            mapping[cl] = -1\n",
    "        else:\n",
    "            mapping[cl] = np.argmax(label_cnt)\n",
    "    prediction = np.zeros(len(y_train), dtype=int)\n",
    "    for cl in range(k):\n",
    "        a = (clusters == cl)\n",
    "        prediction[a] = mapping[cl]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c0c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMC accuracy valid:  0.8587799928375314\n",
      "- Test report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.84      0.40      0.54      1655\n",
      "        true       0.87      0.98      0.92      6723\n",
      "\n",
      "    accuracy                           0.87      8378\n",
      "   macro avg       0.85      0.69      0.73      8378\n",
      "weighted avg       0.86      0.87      0.85      8378\n",
      "\n",
      "- KMC accuracy valid after tuning:  0.8668974573236242\n",
      "Best k:  7\n",
      "- Test report after tuning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.86      0.40      0.55      1655\n",
      "        true       0.87      0.98      0.92      6723\n",
      "\n",
      "    accuracy                           0.87      8378\n",
      "   macro avg       0.86      0.69      0.73      8378\n",
      "weighted avg       0.87      0.87      0.85      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKMC = KMC(k=5)\n",
    "modelKMC.fit(X_train)\n",
    "clusters = modelKMC.predict(X_valid)\n",
    "le = LabelEncoder()\n",
    "\n",
    "Y_valid_encoded = le.fit_transform(Y_valid)\n",
    "y_valid_predKMC = to_labels(clusters, Y_valid_encoded, k=5)\n",
    "y_valid_predKMC_original = le.inverse_transform(y_valid_predKMC)\n",
    "print(\"KMC accuracy valid: \", accuracy_score(Y_valid, y_valid_predKMC_original))\n",
    "\n",
    "y_test_clusters = modelKMC.predict(X_test)\n",
    "y_test_predKMC = to_labels(y_test_clusters, le.transform(Y_test), k=5)\n",
    "y_test_predKMC_original = le.inverse_transform(y_test_predKMC)\n",
    "print(\"- Test report: \\n\", classification_report(Y_test, y_test_predKMC_original))\n",
    "\n",
    "#tuning\n",
    "ks = np.arange(1, 10, 1)\n",
    "best_k = 0\n",
    "best_acc = 0\n",
    "for k in ks:\n",
    "    model = KMC(k=k)\n",
    "    model.fit(X_train)\n",
    "    clusters_valid = model.predict(X_valid)\n",
    "    y_valid_pred = to_labels(clusters_valid, Y_valid_encoded, k=k)\n",
    "    y_valid_pred_original = le.inverse_transform(y_valid_pred)\n",
    "    curr_acc = accuracy_score(Y_valid, y_valid_pred_original)\n",
    "    if curr_acc > best_acc:\n",
    "        best_acc = curr_acc\n",
    "        best_k = k\n",
    "\n",
    "print(\"- KMC accuracy valid after tuning: \", best_acc)\n",
    "print(\"Best k: \", best_k)\n",
    "\n",
    "model_best = KMC(k=best_k)\n",
    "model_best.fit(X_train)\n",
    "clusters_test_best = model_best.predict(X_test)\n",
    "y_test_pred_best = to_labels(clusters_test_best, le.transform(Y_test), k=best_k)\n",
    "y_test_pred_best_original = le.inverse_transform(y_test_pred_best)\n",
    "\n",
    "print(\"- Test report after tuning:\\n\", classification_report(Y_test, y_test_pred_best_original))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
