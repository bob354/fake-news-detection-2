{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import timeit\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "29d01bfd5c2ec232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Pre-cleaning EDA---------------\n",
      "- Training data shape:  (21527, 4)\n",
      "- Training data null count:\n",
      " title         0\n",
      "text          0\n",
      "year_month    0\n",
      "labels        0\n",
      "dtype: int64\n",
      "- Training data duplicate count: 1\n",
      "---------------Post-cleaning EDA---------------\n",
      "- Training data shape:  (21526, 6)\n",
      "- Training data null count:\n",
      " title          0\n",
      "text           0\n",
      "year_month     0\n",
      "labels         0\n",
      "text_length    0\n",
      "full           0\n",
      "dtype: int64\n",
      "- Training data duplicate count: 0\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "valid_df = pd.read_csv('data/valid.csv')\n",
    "\n",
    "#pre-cleaning EDA\n",
    "print(\"---------------Pre-cleaning EDA---------------\")\n",
    "print(\"- Training data shape: \", train_df.shape)\n",
    "print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "counts = train_df['labels'].value_counts()\n",
    "# fig1 = go.Figure(go.Bar(x=counts.index, y=counts.values))\n",
    "# fig1.update_layout(title=\"Label counts\")\n",
    "# fig1.write_html(\"fig1.html\")\n",
    "train_df['text_length'] = train_df['text'].str.split().str.len()\n",
    "# fig2 = px.histogram(train_df, x='text_length', nbins=50, title=\"Text Length Distribution\")\n",
    "# fig2.write_html(\"fig2.html\")\n",
    "# fig2.show()\n",
    "\n",
    "#clean\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['text'] = df['text'].apply(clean_text)\n",
    "    df['title'] = df['title'].apply(clean_text)\n",
    "    df['full'] = df['text'] + ' ' + df['title']\n",
    "    df['full'] = df['full'].str.strip()\n",
    "train_df = train_df.drop_duplicates(subset='full', keep='first')\n",
    "\n",
    "#post-cleaning EDA\n",
    "print(\"---------------Post-cleaning EDA---------------\")\n",
    "print(\"- Training data shape: \", train_df.shape)\n",
    "print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "\n",
    "#feature extract\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_df['full'])\n",
    "X_test = tfidf.transform(test_df['full'])\n",
    "X_valid = tfidf.transform(valid_df['full'])\n",
    "Y_train = np.array(train_df['labels'])\n",
    "Y_test = np.array(test_df['labels'])\n",
    "Y_valid = np.array(valid_df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4072201",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "57615195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self.alpha = alpha\n",
    "        self.classes = None\n",
    "        self.class_logprior = None      \n",
    "        self.feature_logprob = None  \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.classes = np.unique(Y)\n",
    "\n",
    "        temp = []\n",
    "        for c in self.classes:   \n",
    "            temp.append(np.sum(Y == c))\n",
    "        class_cnt = np.array(temp)\n",
    "        self.class_logprior = np.log(class_cnt / Y.shape[0])\n",
    "\n",
    "        smoothed_fc = []\n",
    "        for c in self.classes:\n",
    "            X_c = X[Y == c]\n",
    "            fc = np.array(X_c.sum(axis=0)).ravel() + self.alpha\n",
    "            smoothed_fc.append(fc)\n",
    "        smoothed_fc = np.array(smoothed_fc)\n",
    "        norm = smoothed_fc.sum(axis=1).reshape(-1, 1)\n",
    "        self.feature_logprob = np.log(smoothed_fc / norm)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        jll = X.dot(self.feature_logprob.T) + self.class_logprior\n",
    "        return self.classes[np.argmax(jll, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a1975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Multinomial NB accuracy valid:  0.8670168318013609\n",
      "- Average training time: 0.015014388000126928\n",
      "- Test report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.61      0.94      0.74      1655\n",
      "        true       0.98      0.85      0.91      6723\n",
      "\n",
      "    accuracy                           0.87      8378\n",
      "   macro avg       0.79      0.89      0.82      8378\n",
      "weighted avg       0.91      0.87      0.88      8378\n",
      "\n",
      "- Multinomial NB accuracy test after tuning:  0.8704941513487706\n",
      "-Best parameter: alpha = 2.500000000000001\n",
      "-Test report after tunning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.61      0.93      0.74      1655\n",
      "        true       0.98      0.85      0.91      6723\n",
      "\n",
      "    accuracy                           0.87      8378\n",
      "   macro avg       0.80      0.89      0.83      8378\n",
      "weighted avg       0.91      0.87      0.88      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMNB = MultinomialNaiveBayes()\n",
    "time_taken = timeit.timeit(\n",
    "    stmt=\"modelMNB.fit(X_train, Y_train)\",\n",
    "    setup=\"from __main__ import modelMNB, X_train, Y_train\",\n",
    "    number=50\n",
    ")\n",
    "modelMNB.fit(X_train, Y_train)\n",
    "y_valid_predMNB = modelMNB.predict(X_valid)\n",
    "print(\"- Multinomial NB accuracy valid: \", accuracy_score(Y_valid, y_valid_predMNB))\n",
    "print(\"- Average training time:\", time_taken / 50)\n",
    "y_test_predMNB = modelMNB.predict(X_test)\n",
    "print(\"- Test report: \\n\", classification_report(Y_test, y_test_predMNB))\n",
    "\n",
    "#fine tuning\n",
    "best_alpha = 0\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "alphas = np.arange(1.5, 3.01, 0.05)\n",
    "for a in alphas:\n",
    "    modelMNB = MultinomialNaiveBayes(alpha=a)\n",
    "    modelMNB.fit(X_train, Y_train)\n",
    "    y_test_predMNB = modelMNB.predict(X_test)\n",
    "    curr_acc = accuracy_score(Y_test, y_test_predMNB)\n",
    "    if (curr_acc > best_acc):\n",
    "        best_acc = curr_acc\n",
    "        best_alpha = a\n",
    "        best_pred = y_test_predMNB\n",
    "print(\"- Multinomial NB accuracy test after tuning: \", best_acc)\n",
    "print(\"-Best parameter: alpha =\", best_alpha)\n",
    "print(\"-Test report after tunning:\\n\", classification_report(Y_test, y_test_predMNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6302d",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "22f00762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.X_train = X\n",
    "        self.Y_train = Y\n",
    "    \n",
    "    @staticmethod\n",
    "    def dist_pp(z, x):\n",
    "        z = np.array(z.toarray()).ravel()\n",
    "        x = np.array(x.toarray()).ravel()\n",
    "        d = z - x\n",
    "        return np.sum(d * d)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dist_ps_naive(z, X):\n",
    "        N = X.shape[0]\n",
    "        res = np.zeros((1, N))\n",
    "        for i in range(N):\n",
    "            res[0][i] = KNN.dist_pp(z, X[i])\n",
    "        return res\n",
    "    \n",
    "    def predict1(self, x):\n",
    "        dist = KNN.dist_ps_naive(x, self.X_train).ravel()\n",
    "        k_indices = np.argsort(dist)[:self.k]\n",
    "        k_nearest_labels = [self.Y_train[i] for i in k_indices]\n",
    "        values, cnt = np.unique(k_nearest_labels, return_counts=True)\n",
    "        return values[np.argmax(cnt)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict1(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "727c0c1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m modelKNN = KNN()\n\u001b[32m      2\u001b[39m modelKNN.fit(X_train, Y_train)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y_valid_predKNN = \u001b[43mmodelKNN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKNN accuracy: \u001b[39m\u001b[33m\"\u001b[39m, accuracy_score(Y_valid, y_valid_predKNN))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mKNN.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mKNN.predict1\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict1\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     dist = \u001b[43mKNN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdist_ps_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m.ravel()\n\u001b[32m     28\u001b[39m     k_indices = np.argsort(dist)[:\u001b[38;5;28mself\u001b[39m.k]\n\u001b[32m     29\u001b[39m     k_nearest_labels = [\u001b[38;5;28mself\u001b[39m.Y_train[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m k_indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mKNN.dist_ps_naive\u001b[39m\u001b[34m(z, X)\u001b[39m\n\u001b[32m     21\u001b[39m res = np.zeros((\u001b[32m1\u001b[39m, N))\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     res[\u001b[32m0\u001b[39m][i] = \u001b[43mKNN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdist_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mKNN.dist_pp\u001b[39m\u001b[34m(z, x)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdist_pp\u001b[39m(z, x):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     z = np.array(\u001b[43mz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m).ravel()\n\u001b[32m     14\u001b[39m     x = np.array(x.toarray()).ravel()\n\u001b[32m     15\u001b[39m     d = z - x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Tin\\code\\UETTTTTTTTTTTTTTTTTTTTTTT\\Lab\\Fake news detection 2\\.venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:996\u001b[39m, in \u001b[36m_cs_matrix.toarray\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    995\u001b[39m     order = \u001b[38;5;28mself\u001b[39m._swap(\u001b[33m'\u001b[39m\u001b[33mcf\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out.flags.c_contiguous \u001b[38;5;129;01mor\u001b[39;00m out.flags.f_contiguous):\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mOutput array must be C or F contiguous\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Tin\\code\\UETTTTTTTTTTTTTTTTTTTTTTT\\Lab\\Fake news detection 2\\.venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:1530\u001b[39m, in \u001b[36m_spbase._process_toarray_args\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m   1528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "modelKNN = KNN()\n",
    "modelKNN.fit(X_train, Y_train)\n",
    "y_valid_predKNN = modelKNN.predict(X_valid)\n",
    "print(\"KNN accuracy: \", accuracy_score(Y_valid, y_valid_predKNN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
