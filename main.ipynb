{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T04:03:22.386478Z",
     "start_time": "2025-09-18T04:03:22.055540Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import timeit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29d01bfd5c2ec232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "valid_df = pd.read_csv('data/valid.csv')\n",
    "\n",
    "#pre-cleaning EDA\n",
    "# print(\"---------------Pre-cleaning EDA---------------\")\n",
    "# print(\"- Training data shape: \", train_df.shape)\n",
    "# print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "# print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "counts = train_df['labels'].value_counts()\n",
    "train_df['text_length'] = train_df['text'].str.split().str.len()\n",
    "\n",
    "#clean\n",
    "stopwords = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am',\n",
    "    'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because',\n",
    "    'been', 'before', 'being', 'below', 'between', 'both', 'but',\n",
    "    'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\",\n",
    "    'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    "    'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has',\n",
    "    \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\",\n",
    "    \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him',\n",
    "    'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\",\n",
    "    \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its',\n",
    "    'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my',\n",
    "    'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only',\n",
    "    'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out',\n",
    "    'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\",\n",
    "    \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "    'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves',\n",
    "    'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\",\n",
    "    \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too',\n",
    "    'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\",\n",
    "    \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\",\n",
    "    'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who',\n",
    "    \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would',\n",
    "    \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your',\n",
    "    'yours', 'yourself', 'yourselves'\n",
    "]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    filtered = []\n",
    "    for w in words:\n",
    "        if w not in stopwords and len(w) > 2 and w.isalpha():\n",
    "            filtered.append(w)\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['text'] = df['text'].apply(clean_text).apply(remove_stopwords)\n",
    "    df['title'] = df['title'].apply(clean_text).apply(remove_stopwords)\n",
    "    df['full'] = df['text'] + ' ' + df['title']\n",
    "    df['full'] = df['full'].str.strip()\n",
    "train_df = train_df.drop_duplicates(subset='full', keep='first')\n",
    "\n",
    "#tackle labels imbalance\n",
    "train_df = pd.concat([train_df, train_df[train_df['labels'] == 'true']], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#post-cleaning EDA\n",
    "# print(\"---------------Post-cleaning EDA---------------\")\n",
    "# print(\"- Training data shape: \", train_df.shape)\n",
    "# print(\"- Training data null count:\\n\", train_df.isnull().sum())\n",
    "# print(\"- Training data duplicate count:\", train_df.duplicated().sum())\n",
    "\n",
    "#feature extract\n",
    "bow = CountVectorizer(stop_words=stopwords, max_features=5000)\n",
    "X_train = bow.fit_transform(train_df['full']).toarray()\n",
    "X_test = bow.transform(test_df['full']).toarray()\n",
    "X_valid = bow.transform(valid_df['full']).toarray()\n",
    "Y_train = np.array(train_df['labels'])\n",
    "Y_test = np.array(test_df['labels'])\n",
    "Y_valid = np.array(valid_df['labels'])\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4072201",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57615195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.classes = None\n",
    "        self.class_prior = None\n",
    "        self.prob = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.classes = np.unique(Y)\n",
    "\n",
    "        class_cnt = []\n",
    "        for c in self.classes:\n",
    "            class_cnt.append(len(Y[Y==c]))\n",
    "        self.class_prior = np.log(np.array(class_cnt) / len(Y))\n",
    "\n",
    "        words_cnt = []\n",
    "        for c in self.classes:\n",
    "            Xc = X[Y == c]\n",
    "            cnt = np.array(Xc.sum(axis=0)).ravel() + self.alpha\n",
    "            words_cnt.append(cnt)\n",
    "        total = np.array(words_cnt).sum(axis=1).reshape(-1, 1)\n",
    "        self.prob = np.log(words_cnt / total)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = X.dot(self.prob.T) + self.class_prior\n",
    "        return self.classes[np.argmax(prediction, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "468a1975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Multinomial NB accuracy valid:  0.9023516772114122\n",
      "- Average training time: 0.4288096660003066\n",
      "- Test report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.69      0.93      0.79      1655\n",
      "        true       0.98      0.90      0.94      6723\n",
      "\n",
      "    accuracy                           0.90      8378\n",
      "   macro avg       0.83      0.91      0.86      8378\n",
      "weighted avg       0.92      0.90      0.91      8378\n",
      "\n",
      "- Multinomial NB accuracy test after tuning:  0.9031988541417999\n",
      "-Best parameter: alpha = 2.8500000000000014\n",
      "-Test report after tunning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.69      0.93      0.79      1655\n",
      "        true       0.98      0.90      0.94      6723\n",
      "\n",
      "    accuracy                           0.90      8378\n",
      "   macro avg       0.84      0.91      0.86      8378\n",
      "weighted avg       0.92      0.90      0.91      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMNB = MultinomialNaiveBayes()\n",
    "time_taken = timeit.timeit(\n",
    "    stmt=\"modelMNB.fit(X_train, Y_train)\",\n",
    "    setup=\"from __main__ import modelMNB, X_train, Y_train\",\n",
    "    number=50\n",
    ")\n",
    "modelMNB.fit(X_train, Y_train)\n",
    "y_valid_predMNB = modelMNB.predict(X_valid)\n",
    "print(\"- Multinomial NB accuracy valid: \", accuracy_score(Y_valid, y_valid_predMNB))\n",
    "print(\"- Average training time:\", time_taken / 50)\n",
    "y_test_predMNB = modelMNB.predict(X_test)\n",
    "print(\"- Test report: \\n\", classification_report(Y_test, y_test_predMNB))\n",
    "\n",
    "#fine tuning\n",
    "best_alpha = 0\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "alphas = np.arange(1.5, 3.01, 0.05)\n",
    "for a in alphas:\n",
    "    modelMNB = MultinomialNaiveBayes(alpha=a)\n",
    "    modelMNB.fit(X_train, Y_train)\n",
    "    y_test_predMNB = modelMNB.predict(X_test)\n",
    "    curr_acc = accuracy_score(Y_test, y_test_predMNB)\n",
    "    if (curr_acc > best_acc):\n",
    "        best_acc = curr_acc\n",
    "        best_alpha = a\n",
    "        best_pred = y_test_predMNB\n",
    "print(\"- Multinomial NB accuracy test after tuning: \", best_acc)\n",
    "print(\"-Best parameter: alpha =\", best_alpha)\n",
    "print(\"-Test report after tunning:\\n\", classification_report(Y_test, y_test_predMNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6302d",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f00762",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def distance(x, y):\n",
    "    if hasattr(x, 'toarray'):\n",
    "        x = x.toarray()\n",
    "    x = x.ravel()\n",
    "    y = y.ravel()\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "def to_labels(clusters, y_train, k):\n",
    "    mapping = {}\n",
    "    for cl in range(k):\n",
    "        mask = (clusters == cl)\n",
    "        label_cnt = np.bincount(y_train[mask])\n",
    "        if len(label_cnt == 0):\n",
    "            mapping[cl] = -1\n",
    "        else:\n",
    "            mapping[cl] = np.argmax(label_cnt)\n",
    "    prediction = np.zeros(len(y_train), dtype=int)\n",
    "    for cl in range(k):\n",
    "        mask = (clusters == cl)\n",
    "        prediction[mask] = mapping[cl]\n",
    "    return prediction\n",
    "\n",
    "class KMC:\n",
    "    def __init__(self, k=3, max_iters=100, tol=0.0001):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "    \n",
    "    def assign_clusters(self, X):\n",
    "        temp = []\n",
    "        for x in X:\n",
    "            min_dist = 1000000000.0\n",
    "            closest_cluster = -1\n",
    "            for i, c in enumerate(self.centroids):\n",
    "                curr_dist = distance(x, c)\n",
    "                if curr_dist < min_dist:\n",
    "                    min_dist = curr_dist\n",
    "                    closest_cluster = i\n",
    "            temp.append(closest_cluster)\n",
    "        return np.array(temp)\n",
    "\n",
    "    def compute_centroids(self, X, clusters):\n",
    "        new_centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            points = X[clusters == i]\n",
    "            if len(points) > 0:\n",
    "                new_centroids[i] = points.mean(axis=0)\n",
    "            else:\n",
    "                new_centroids[i] = self.centroids[i]\n",
    "        return new_centroids\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if hasattr(X, 'toarray'):\n",
    "            X.toarray()\n",
    "        centroids_id = np.random.choice(X.shape[0], size=self.k, replace=False)\n",
    "        self.centroids = X[centroids_id]\n",
    "        for i in range(self.max_iters):\n",
    "            clusters = self.assign_clusters(X)\n",
    "            new_centroids = self.compute_centroids(X, clusters)\n",
    "            if np.linalg.norm(new_centroids - self.centroids) < self.tol:\n",
    "                break\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "    def predict(self, X):\n",
    "        if hasattr(X, 'toarray'):\n",
    "            X.toarray()\n",
    "        return self.assign_clusters(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "727c0c1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m modelKMC = KMC(k=\u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodelKMC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m clusters = modelKMC.predict(X_valid)\n\u001b[32m      4\u001b[39m l = LabelEncoder()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mKMC.fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_iters):\n\u001b[32m     60\u001b[39m     clusters = \u001b[38;5;28mself\u001b[39m.assign_clusters(X)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     new_centroids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_centroids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.linalg.norm(new_centroids - \u001b[38;5;28mself\u001b[39m.centroids) < \u001b[38;5;28mself\u001b[39m.tol:\n\u001b[32m     63\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mKMC.compute_centroids\u001b[39m\u001b[34m(self, X, clusters)\u001b[39m\n\u001b[32m     47\u001b[39m points = X[clusters == i]\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(points) > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     new_centroids[i] = \u001b[43mpoints\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     51\u001b[39m     new_centroids[i] = \u001b[38;5;28mself\u001b[39m.centroids[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:101\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m um.clip(a, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, out=out, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    102\u001b[39m     arr = asanyarray(a)\n\u001b[32m    104\u001b[39m     is_float16_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "modelKMC = KMC(k=5)\n",
    "modelKMC.fit(X_train)\n",
    "clusters = modelKMC.predict(X_valid)\n",
    "l = LabelEncoder()\n",
    "\n",
    "encoded = l.fit_transform(Y_valid)\n",
    "y_valid_predKMC = to_labels(clusters, encoded, k=3)\n",
    "y_valid_predKMC_original = l.inverse_transform(y_valid_predKMC)\n",
    "print(\"KMC accuracy valid: \", accuracy_score(Y_valid, y_valid_predKMC_original))\n",
    "\n",
    "y_test_clusters = modelKMC.predict(X_test)\n",
    "y_test_predKMC = to_labels(y_test_clusters, l.transform(Y_test), k=5)\n",
    "y_test_predKMC_original = l.inverse_transform(y_test_predKMC)\n",
    "print(\"- Test report: \\n\", classification_report(Y_test, y_test_predKMC_original))\n",
    "\n",
    "#tuning\n",
    "ks = np.arange(5, 9, 2)\n",
    "best_k = 0\n",
    "best_acc = 0\n",
    "for k in ks:\n",
    "    model = KMC(k=k)\n",
    "    model.fit(X_train)\n",
    "    clusters_valid = model.predict(X_valid)\n",
    "    y_valid_pred = to_labels(clusters_valid, encoded, k=k)\n",
    "    y_valid_pred_og = l.inverse_transform(y_valid_pred)\n",
    "    curr_acc = accuracy_score(Y_valid, y_valid_pred_og)\n",
    "    if curr_acc > best_acc:\n",
    "        best_acc = curr_acc\n",
    "        best_k = k\n",
    "\n",
    "print(\"- KMC accuracy valid after tuning: \", best_acc)\n",
    "print(\"Best k: \", best_k)\n",
    "\n",
    "model_best = KMC(k=best_k)\n",
    "model_best.fit(X_train)\n",
    "clusters_test_best = model_best.predict(X_test)\n",
    "y_test_pred_best = to_labels(clusters_test_best, l.transform(Y_test), k=best_k)\n",
    "y_test_pred_best_original = l.inverse_transform(y_test_pred_best)\n",
    "\n",
    "print(\"- Test report after tuning:\\n\", classification_report(Y_test, y_test_pred_best_original))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
